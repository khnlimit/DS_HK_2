{
 "metadata": {
  "name": "",
  "signature": "sha256:6c04f415fc0e873047983fb7d26b32179f1341933970fbad54356ee956666554"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%javascript\n",
      "function is_local(){\n",
      "  return (document.location.hostname == \"localhost\" || document.location.hostname == '127.0.0.1')\n",
      "}\n",
      "var url = is_local() ? \"http://localhost:8000/theme/custom.js\" : \"http://odhk.github.io/hyrule_theme/custom.js\"\n",
      "$.getScript(url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "javascript": [
        "function is_local(){\n",
        "  return (document.location.hostname == \"localhost\" || document.location.hostname == '127.0.0.1')\n",
        "}\n",
        "var url = is_local() ? \"http://localhost:8000/theme/custom.js\" : \"http://odhk.github.io/hyrule_theme/custom.js\"\n",
        "$.getScript(url)"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Javascript at 0x2a7da90>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> The virtue of binary is that it's the simplest possible way of representing numbers. Anything else is more complicated. You can catch errors with it, it's unambiguous in its reading, there are lots of good things about binary. So it is very, very simple once you learn how to read it.\n",
      "\n",
      "<footer>~ George M. Whitesides</footer>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/agenda.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Logistic Regression\n",
      "1. Outcome Variables\n",
      "1. Error Terms\n",
      "1. Interpreting Results\n",
      "\n",
      "**Labs:**\n",
      "1. Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/theory.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "|   \t|continuous\t|categorical   \t|\n",
      "|:-:\t|:-:\t|:-:\t|\n",
      "|**supervised**   \t|regression   \t|**classification**   \t|\n",
      "|**unsupervised**   \t|dimension reduction   \t|clustering   \t|"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A generalization of the linear regression model to classification problems.\n",
      "* A discriminative classification algorithm, result does not depend completely the data set."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In **linear regression**, we used a set of covariates to predict the value of a (continuous) outcome variable.\n",
      "In **logistic regression**, we use a set of covariates to predict probabilities of (binary) class membership. These probabilities are then mapped to class labels, thus solving the classification problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Probability predictions look like this."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/logistic_regression.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* ** Y ** : Probability of belonging to class\n",
      "* ** X ** : Value of independent variable"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Probabilities are \u201csnapped\u201d to class labels (eg by threshholding at 50%)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/logistic_regression_snap.png)\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that Logistic Regression is primarily used to solve a binary classification problem.\n",
      "\n",
      "Examples:\n",
      "* Was this credit transaction fraudulent? (Y/N)\n",
      "* User a boy or a girl?\n",
      "* Do I have x disease?\n",
      "* Should this stock be bought or sold?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The logistic regression model is an extension of the linear regression model, with a couple of important differences:\n",
      "    \n",
      "* Difference 1: Outcome Variables\n",
      "* Difference 2: Error Terms\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Outcome Variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The key variable in any regression problem is the **conditional mean** of the outcome variable y given the value of the covariate x:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ E(y|x) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In linear regression, we assume that this conditional\n",
      "mean is a linear function taking values in (-\u221e, +\u221e):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ E(y|x) = \\alpha + \\beta x $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Q: How is this different from just using a linear\n",
      "regression to solve a classification problem?**\n",
      "\n",
      "A: If the original values are not scaled correctly, then the\n",
      "results for data once classified 0 may be reclassified as 1.\n",
      "\n",
      "**We don\u2019t want that to happen!**\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In logistic regression, we\u2019ve seen that the conditional mean of the outcome variable takes values only in the unit interval [0, 1].\n",
      "\n",
      "0 = negative class, 1 = positive class\n",
      "\n",
      "The first step in extending the linear regression model to logistic regression is to map the outcome variable E(y|x) into the unit interval.\n",
      "\n",
      "By using a transformation called the logistic function:\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ E(y|x) = \\pi(x) = {e^{\\alpha + \\beta x} \\over 1+e^{\\alpha + \\beta x}} = {1 \\over 1+e^{-(\\alpha + \\beta x)}} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We\u2019ve already seen what this looks like:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/logistic_regression.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For any value of $x, y$ is in the interval $[0, 1]$ This is a nonlinear transformation!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The logit function is an important transformation of the logistic function. Notice that it returns the linear model!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ g(x) = \\ln\\left(\\frac{\\pi(x)}{1-\\pi(x)}\\right) = \\alpha + \\beta x $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The logit function is also called the log-odds function. This name hints at its usefulness in interpreting our results. We will see why shortly.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/theory.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Error Terms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second difference between linear regression and the logistic regression model is in the error term.\n",
      "\n",
      "One of the key assumptions of linear regression is that the error terms follow independent Gaussian distributions with zero mean and constant variance:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ \\epsilon \\sim N(0,\\sigma^2) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In logistic regression, the outcome variable can take only two values: 0 or 1.\n",
      "\n",
      "It\u2019s easy to show from this that instead of following a Gaussian distribution, the error term in logistic regression follows a Bernoulli distribution:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ \\epsilon \\sim B(0,\\pi(1 - \\pi))) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the same distribution followed by a coin toss. Think about why this makes sense!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Bernoulli Distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Bernoulli distribution is a discrete distribution having two possible outcomes labelled by $n=0$ and $n=1$ in which $n=1$ (\"success\") occurs with probability $p$ and $n=0$ (\"failure\") occurs with probability $q=1-p$, where $0<p<1$. It therefore has probability density function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ f(k;p) = \\begin{cases}\n",
      "    p & \\text{if } k=1 \\\\\\\\ \n",
      "    1-p & \\text{if } k=0\n",
      "\\end{cases}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy.stats\n",
      "from scipy.stats import bernoulli"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bernoulli.rvs(0.6, size=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "array([0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
        "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
        "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
        "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
        "       0, 1, 1, 1, 0, 1, 0, 1])"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.arange(2)\n",
      "\n",
      "colors = matplotlib.rcParams['axes.color_cycle']\n",
      "plt.figure(figsize=(20,8))\n",
      "for i, p in enumerate([0.1, 0.2, 0.6, 0.7]):\n",
      "    ax = plt.subplot(1, 4, i+1)\n",
      "    plt.bar(a, bernoulli.pmf(a, p), label=p, color=colors[i], alpha=0.5)\n",
      "    ax.xaxis.set_ticks(a)\n",
      "\n",
      "    plt.legend(loc=0)\n",
      "    if i == 0:\n",
      "        plt.ylabel(\"PDF at $k$\")\n",
      "    \n",
      "\n",
      "plt.suptitle(\"Bernoulli probability\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<matplotlib.text.Text at 0x272a9d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAABI4AAAIICAYAAAAIUqVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x272a550>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "An Aside : GLM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These two key differences define the logistic regression model, and they also lead us to a kind of unification of regression techniques called **generalized linear models**.\n",
      "\n",
      "Briefly, GLMs generalize the distribution of the error term, and allow the conditional mean of the response variable to be related to the linear model by a link function.\n",
      "\n",
      "In the present case, the error term follows a Bernoulli distribution, and the logit is the link function that connects us to the linear predictor."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ g(x) = \\ln\\left(\\frac{\\pi(x)}{1-\\pi(x)}\\right) = \\alpha + \\beta x $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the Bernoulli distribution and the logit function share a common parameter \u03c0, we say that the logit is the canonical link function for the Bernoulli distribution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/theory.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Interpreting Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In linear regression, the parameter \u03b2 represents the change in the response variable for a unit change in the\n",
      "covariate. \n",
      "\n",
      "In logistic regression, \u03b2 represents the change in the logit function for a unit change in the covariate.\n",
      "\n",
      "Interpreting this change in the logit function requires another definition first."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Your independent variables $X_i$ can be continuous or binary. The regression coefficients $b_i$ can be exponentiated to give you the change in odds of $Y$ per change in $X_i$, i.e.,"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In English, you can say that the odds of $Y=1$ increase by a factor of $e^{b_i}$ per unit change in $X$i."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The odds of an event are given by the ratio of the probability of the event by its complement:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ O(x=1) = \\frac{\\pi(1)}{(1-\\pi(1))}$$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The odds ratio of a binary event is given by the odds of the event divided by the odds of its complement:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ O R={O(x=1) \\over O(x=0)}={ \\pi(1)/[1-\\pi(1)] \\over \\pi(0)/[1-\\pi(0)] }$$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Substituting the definition of $\u03c0(x)$ into this equation yields (after some algebra),\n",
      "\n",
      "$$ O R = e^\u03b2 $$\n",
      "\n",
      "This simple relationship between the odds ratio and the parameter $\u03b2$ is what makes logistic regression such a powerful tool."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Q: So how do we interpret this?**\n",
      "\n",
      "A: The odds ratio of a binary event gives the increase in likelihood of an outcome if the event occurs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we are interested in mobile purchase behavior. Let y be a class label denoting purchase/no purchase, and let x denote a mobile OS (for example, Android).\n",
      "\n",
      "In this case, an odds ratio of 2 (eg, $\u03b2 = log(2)$) indicates that a purchase is twice as likely for an Android user as for a non-Android user."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/code.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Work through the Logistic Regression model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Set some Pandas options\n",
      "pd.set_option('max_columns', 30)\n",
      "pd.set_option('max_rows', 20)\n",
      "\n",
      "# Store data in a consistent place\n",
      "DATA_DIR = '../data/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see if we can use logistic regression to predict what kinds of beer people like."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "url = 'http://www-958.ibm.com/software/analytics/manyeyes/datasets/af-er-beer-dataset/versions/1.txt'\n",
      "beer = pd.read_csv(url, delimiter=\"\\t\")\n",
      "beer = beer.dropna()\n",
      "def good(x):\n",
      "    if x > 4.3:\n",
      "        return 1\n",
      "    else:\n",
      "        return 0\n",
      "\n",
      "beer['Good'] = beer['WR'].apply(good)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see how fit goes using just Reviews and ABV."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "\n",
      "logm = linear_model.LogisticRegression()\n",
      "\n",
      "X = beer[ ['Reviews', 'ABV'] ].values\n",
      "y = beer['Good'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logm.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logm.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logm.score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "0.62393162393162394"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We end up with a value around .62, which is only slightly higher than random (random = .5, like a coin flip).\n",
      "\n",
      "Question: What data can we use in this data frame to determine what kind of beer it is? This may be a better indicator! Note, we can use regex's to create a new column."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/voronoi.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Write a function that groups our beers together using regex (example here):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "# If this is true, then there was a match!\n",
      "re.search('Apple', 'Apple Computer') != None\n",
      "\n",
      "# or you can use the str.contains method\n",
      "beer['Name'].str.contains('Pliny')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "0    False\n",
        "1     True\n",
        "2     True\n",
        "3    False\n",
        "4    False\n",
        "5    False\n",
        "7    False\n",
        "8    False\n",
        "...\n",
        "242    False\n",
        "243    False\n",
        "244    False\n",
        "245    False\n",
        "246    False\n",
        "247    False\n",
        "248    False\n",
        "249    False\n",
        "Name: Name, Length: 234, dtype: bool"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll be grouping our beers into **Ale**, **Stout**, **IPA**, and **Lager**. \n",
      "\n",
      "Of course, due to how we handle our data (numpy arrays), these have to be vectorized into four separate columns. \n",
      "\n",
      "Finally, we can create a logistic regression model using these four to predict if \"Good\" = 0 or 1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = beer[ ['Ale', 'Stout', 'IPA', 'Lager'] ].values\n",
      "y = beer['Good'].values\n",
      "\n",
      "logm.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And consider looking again at the `coef_`, `intercept_`, etc. We can consider precision based on `|predicted - actual|` as well as looking at `.score()`.\n",
      "\n",
      "Consider using `set_params(penalty = 'l1')` to see how your results change, and if this has become more precise or not. How does this align with what we discussed with `l1` and `l2` norm in lecture?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/voronoi.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Homework"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Spend some time this week to predict the 2012 salary per player using the 2011 data in the data set below:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> http://cl.ly/RUED (note curl won't work here)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You'll need to \"munge\" through the data by plotting various data against Salary to understand the relationship for each value in order to interpret the best model. I'd focus around these to start with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ [\"HR\", \"RBI\", 'R', \"G\", \"SB\", \"salary\", 'height', 'weight', 'yearID'] ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[['HR', 'RBI', 'R', 'G', 'SB', 'salary', 'height', 'weight', 'yearID']]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "but jump around and look at the variety of data available (and use feature selection!) to determine how significant the data available is in predicting salary.\n",
      "\n",
      "Keep in mind that you cannot have a NEGATIVE salary, so if you have a negative prediction, whoops. :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/resources.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Resources"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [Regression Analysis by Example](http://type.hk:2551/calibre/browse/book/294) (**Chapter 12**) - Samprit Chatterjee"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Articles"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [The Bernoulli distribution mean and variance](http://hawaiireedlab.com/wpress/?p=1019)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Code"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [Overview with plots of statistical distributions](http://nbviewer.ipython.org/urls/gist.github.com/mattions/6113437/raw/c5468ea930d6960225d83e112d7f3d00d9c13398/Exploring+different+distribution.ipynb)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}